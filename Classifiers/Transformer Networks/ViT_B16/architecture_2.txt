=========================Layer Names=========================
0: vitb16.class_token	(freezed till here)
1: vitb16.conv_proj.weight	(freezed till here)
2: vitb16.conv_proj.bias	(freezed till here)
3: vitb16.encoder.pos_embedding	(freezed till here)
4: vitb16.encoder.layers.encoder_layer_0.ln_1.weight	(freezed till here)
5: vitb16.encoder.layers.encoder_layer_0.ln_1.bias	(freezed till here)
6: vitb16.encoder.layers.encoder_layer_0.self_attention.in_proj_weight	(freezed till here)
7: vitb16.encoder.layers.encoder_layer_0.self_attention.in_proj_bias	(freezed till here)
8: vitb16.encoder.layers.encoder_layer_0.self_attention.out_proj.weight	(freezed till here)
9: vitb16.encoder.layers.encoder_layer_0.self_attention.out_proj.bias	(freezed till here)
10: vitb16.encoder.layers.encoder_layer_0.ln_2.weight	(freezed till here)
11: vitb16.encoder.layers.encoder_layer_0.ln_2.bias	(freezed till here)
12: vitb16.encoder.layers.encoder_layer_0.mlp.0.weight	(freezed till here)
13: vitb16.encoder.layers.encoder_layer_0.mlp.0.bias	(freezed till here)
14: vitb16.encoder.layers.encoder_layer_0.mlp.3.weight	(freezed till here)
15: vitb16.encoder.layers.encoder_layer_0.mlp.3.bias	(freezed till here)
16: vitb16.encoder.layers.encoder_layer_1.ln_1.weight	(freezed till here)
17: vitb16.encoder.layers.encoder_layer_1.ln_1.bias	(freezed till here)
18: vitb16.encoder.layers.encoder_layer_1.self_attention.in_proj_weight	(freezed till here)
19: vitb16.encoder.layers.encoder_layer_1.self_attention.in_proj_bias	(freezed till here)
20: vitb16.encoder.layers.encoder_layer_1.self_attention.out_proj.weight	(freezed till here)
21: vitb16.encoder.layers.encoder_layer_1.self_attention.out_proj.bias	(freezed till here)
22: vitb16.encoder.layers.encoder_layer_1.ln_2.weight	(freezed till here)
23: vitb16.encoder.layers.encoder_layer_1.ln_2.bias	(freezed till here)
24: vitb16.encoder.layers.encoder_layer_1.mlp.0.weight	(freezed till here)
25: vitb16.encoder.layers.encoder_layer_1.mlp.0.bias	(freezed till here)
26: vitb16.encoder.layers.encoder_layer_1.mlp.3.weight	(freezed till here)
27: vitb16.encoder.layers.encoder_layer_1.mlp.3.bias	(freezed till here)
28: vitb16.encoder.layers.encoder_layer_2.ln_1.weight	(freezed till here)
29: vitb16.encoder.layers.encoder_layer_2.ln_1.bias	(freezed till here)
30: vitb16.encoder.layers.encoder_layer_2.self_attention.in_proj_weight	(freezed till here)
31: vitb16.encoder.layers.encoder_layer_2.self_attention.in_proj_bias	(freezed till here)
32: vitb16.encoder.layers.encoder_layer_2.self_attention.out_proj.weight	(freezed till here)
33: vitb16.encoder.layers.encoder_layer_2.self_attention.out_proj.bias	(freezed till here)
34: vitb16.encoder.layers.encoder_layer_2.ln_2.weight	(freezed till here)
35: vitb16.encoder.layers.encoder_layer_2.ln_2.bias	(freezed till here)
36: vitb16.encoder.layers.encoder_layer_2.mlp.0.weight	(freezed till here)
37: vitb16.encoder.layers.encoder_layer_2.mlp.0.bias	(freezed till here)
38: vitb16.encoder.layers.encoder_layer_2.mlp.3.weight	(freezed till here)
39: vitb16.encoder.layers.encoder_layer_2.mlp.3.bias	(freezed till here)
40: vitb16.encoder.layers.encoder_layer_3.ln_1.weight	(freezed till here)
41: vitb16.encoder.layers.encoder_layer_3.ln_1.bias	(freezed till here)
42: vitb16.encoder.layers.encoder_layer_3.self_attention.in_proj_weight	(freezed till here)
43: vitb16.encoder.layers.encoder_layer_3.self_attention.in_proj_bias	(freezed till here)
44: vitb16.encoder.layers.encoder_layer_3.self_attention.out_proj.weight	(freezed till here)
45: vitb16.encoder.layers.encoder_layer_3.self_attention.out_proj.bias	(freezed till here)
46: vitb16.encoder.layers.encoder_layer_3.ln_2.weight	(freezed till here)
47: vitb16.encoder.layers.encoder_layer_3.ln_2.bias	(freezed till here)
48: vitb16.encoder.layers.encoder_layer_3.mlp.0.weight	(freezed till here)
49: vitb16.encoder.layers.encoder_layer_3.mlp.0.bias	(freezed till here)
50: vitb16.encoder.layers.encoder_layer_3.mlp.3.weight	(freezed till here)
51: vitb16.encoder.layers.encoder_layer_3.mlp.3.bias	(freezed till here)
52: vitb16.encoder.layers.encoder_layer_4.ln_1.weight	(freezed till here)
53: vitb16.encoder.layers.encoder_layer_4.ln_1.bias	(freezed till here)
54: vitb16.encoder.layers.encoder_layer_4.self_attention.in_proj_weight	(freezed till here)
55: vitb16.encoder.layers.encoder_layer_4.self_attention.in_proj_bias	(freezed till here)
56: vitb16.encoder.layers.encoder_layer_4.self_attention.out_proj.weight	(freezed till here)
57: vitb16.encoder.layers.encoder_layer_4.self_attention.out_proj.bias	(freezed till here)
58: vitb16.encoder.layers.encoder_layer_4.ln_2.weight	(freezed till here)
59: vitb16.encoder.layers.encoder_layer_4.ln_2.bias	(freezed till here)
60: vitb16.encoder.layers.encoder_layer_4.mlp.0.weight	(freezed till here)
61: vitb16.encoder.layers.encoder_layer_4.mlp.0.bias	(freezed till here)
62: vitb16.encoder.layers.encoder_layer_4.mlp.3.weight	(freezed till here)
63: vitb16.encoder.layers.encoder_layer_4.mlp.3.bias	(freezed till here)
64: vitb16.encoder.layers.encoder_layer_5.ln_1.weight	(freezed till here)
65: vitb16.encoder.layers.encoder_layer_5.ln_1.bias	(freezed till here)
66: vitb16.encoder.layers.encoder_layer_5.self_attention.in_proj_weight	(freezed till here)
67: vitb16.encoder.layers.encoder_layer_5.self_attention.in_proj_bias	(freezed till here)
68: vitb16.encoder.layers.encoder_layer_5.self_attention.out_proj.weight	(freezed till here)
69: vitb16.encoder.layers.encoder_layer_5.self_attention.out_proj.bias	(freezed till here)
70: vitb16.encoder.layers.encoder_layer_5.ln_2.weight	(freezed till here)
71: vitb16.encoder.layers.encoder_layer_5.ln_2.bias	(freezed till here)
72: vitb16.encoder.layers.encoder_layer_5.mlp.0.weight	(freezed till here)
73: vitb16.encoder.layers.encoder_layer_5.mlp.0.bias	(freezed till here)
74: vitb16.encoder.layers.encoder_layer_5.mlp.3.weight	(freezed till here)
75: vitb16.encoder.layers.encoder_layer_5.mlp.3.bias	(freezed till here)
76: vitb16.encoder.layers.encoder_layer_6.ln_1.weight	(freezed till here)
77: vitb16.encoder.layers.encoder_layer_6.ln_1.bias	(freezed till here)
78: vitb16.encoder.layers.encoder_layer_6.self_attention.in_proj_weight	(freezed till here)
79: vitb16.encoder.layers.encoder_layer_6.self_attention.in_proj_bias	(freezed till here)
80: vitb16.encoder.layers.encoder_layer_6.self_attention.out_proj.weight	(freezed till here)
81: vitb16.encoder.layers.encoder_layer_6.self_attention.out_proj.bias	(freezed till here)
82: vitb16.encoder.layers.encoder_layer_6.ln_2.weight	(freezed till here)
83: vitb16.encoder.layers.encoder_layer_6.ln_2.bias	(freezed till here)
84: vitb16.encoder.layers.encoder_layer_6.mlp.0.weight	(freezed till here)
85: vitb16.encoder.layers.encoder_layer_6.mlp.0.bias	(freezed till here)
86: vitb16.encoder.layers.encoder_layer_6.mlp.3.weight	(freezed till here)
87: vitb16.encoder.layers.encoder_layer_6.mlp.3.bias	(freezed till here)
88: vitb16.encoder.layers.encoder_layer_7.ln_1.weight	(freezed till here)
89: vitb16.encoder.layers.encoder_layer_7.ln_1.bias	(freezed till here)
90: vitb16.encoder.layers.encoder_layer_7.self_attention.in_proj_weight	(freezed till here)
91: vitb16.encoder.layers.encoder_layer_7.self_attention.in_proj_bias	(freezed till here)
92: vitb16.encoder.layers.encoder_layer_7.self_attention.out_proj.weight	(freezed till here)
93: vitb16.encoder.layers.encoder_layer_7.self_attention.out_proj.bias	(freezed till here)
94: vitb16.encoder.layers.encoder_layer_7.ln_2.weight	(freezed till here)
95: vitb16.encoder.layers.encoder_layer_7.ln_2.bias	(freezed till here)
96: vitb16.encoder.layers.encoder_layer_7.mlp.0.weight	(freezed till here)
97: vitb16.encoder.layers.encoder_layer_7.mlp.0.bias	(freezed till here)
98: vitb16.encoder.layers.encoder_layer_7.mlp.3.weight	(freezed till here)
99: vitb16.encoder.layers.encoder_layer_7.mlp.3.bias	(freezed till here)
100: vitb16.encoder.layers.encoder_layer_8.ln_1.weight	(freezed till here)
101: vitb16.encoder.layers.encoder_layer_8.ln_1.bias	(freezed till here)
102: vitb16.encoder.layers.encoder_layer_8.self_attention.in_proj_weight	(freezed till here)
103: vitb16.encoder.layers.encoder_layer_8.self_attention.in_proj_bias	(freezed till here)
104: vitb16.encoder.layers.encoder_layer_8.self_attention.out_proj.weight	(freezed till here)
105: vitb16.encoder.layers.encoder_layer_8.self_attention.out_proj.bias	(freezed till here)
106: vitb16.encoder.layers.encoder_layer_8.ln_2.weight	(freezed till here)
107: vitb16.encoder.layers.encoder_layer_8.ln_2.bias	(freezed till here)
108: vitb16.encoder.layers.encoder_layer_8.mlp.0.weight	(freezed till here)
109: vitb16.encoder.layers.encoder_layer_8.mlp.0.bias	(freezed till here)
110: vitb16.encoder.layers.encoder_layer_8.mlp.3.weight	(freezed till here)
111: vitb16.encoder.layers.encoder_layer_8.mlp.3.bias	(freezed till here)
112: vitb16.encoder.layers.encoder_layer_9.ln_1.weight	(freezed till here)
113: vitb16.encoder.layers.encoder_layer_9.ln_1.bias	(freezed till here)
114: vitb16.encoder.layers.encoder_layer_9.self_attention.in_proj_weight	(freezed till here)
115: vitb16.encoder.layers.encoder_layer_9.self_attention.in_proj_bias	(freezed till here)
116: vitb16.encoder.layers.encoder_layer_9.self_attention.out_proj.weight	(freezed till here)
117: vitb16.encoder.layers.encoder_layer_9.self_attention.out_proj.bias	(freezed till here)
118: vitb16.encoder.layers.encoder_layer_9.ln_2.weight	(freezed till here)
119: vitb16.encoder.layers.encoder_layer_9.ln_2.bias	(freezed till here)
120: vitb16.encoder.layers.encoder_layer_9.mlp.0.weight	(freezed till here)
121: vitb16.encoder.layers.encoder_layer_9.mlp.0.bias	(freezed till here)
122: vitb16.encoder.layers.encoder_layer_9.mlp.3.weight	(freezed till here)
123: vitb16.encoder.layers.encoder_layer_9.mlp.3.bias	(freezed till here)
124: vitb16.encoder.layers.encoder_layer_10.ln_1.weight	(freezed till here)
125: vitb16.encoder.layers.encoder_layer_10.ln_1.bias	(freezed till here)
126: vitb16.encoder.layers.encoder_layer_10.self_attention.in_proj_weight	(freezed till here)
127: vitb16.encoder.layers.encoder_layer_10.self_attention.in_proj_bias	(freezed till here)
128: vitb16.encoder.layers.encoder_layer_10.self_attention.out_proj.weight	(freezed till here)
129: vitb16.encoder.layers.encoder_layer_10.self_attention.out_proj.bias	(freezed till here)
130: vitb16.encoder.layers.encoder_layer_10.ln_2.weight	(freezed till here)
131: vitb16.encoder.layers.encoder_layer_10.ln_2.bias	(freezed till here)
132: vitb16.encoder.layers.encoder_layer_10.mlp.0.weight	(freezed till here)
133: vitb16.encoder.layers.encoder_layer_10.mlp.0.bias	(freezed till here)
134: vitb16.encoder.layers.encoder_layer_10.mlp.3.weight	(freezed till here)
135: vitb16.encoder.layers.encoder_layer_10.mlp.3.bias	(freezed till here)
136: vitb16.encoder.layers.encoder_layer_11.ln_1.weight	(freezed till here)
137: vitb16.encoder.layers.encoder_layer_11.ln_1.bias	(freezed till here)
138: vitb16.encoder.layers.encoder_layer_11.self_attention.in_proj_weight	(freezed till here)
139: vitb16.encoder.layers.encoder_layer_11.self_attention.in_proj_bias	(freezed till here)
140: vitb16.encoder.layers.encoder_layer_11.self_attention.out_proj.weight	(freezed till here)
141: vitb16.encoder.layers.encoder_layer_11.self_attention.out_proj.bias	(freezed till here)
142: vitb16.encoder.layers.encoder_layer_11.ln_2.weight	(freezed till here)
143: vitb16.encoder.layers.encoder_layer_11.ln_2.bias	(freezed till here)
144: vitb16.encoder.layers.encoder_layer_11.mlp.0.weight	(freezed till here)
145: vitb16.encoder.layers.encoder_layer_11.mlp.0.bias	(freezed till here)
146: vitb16.encoder.layers.encoder_layer_11.mlp.3.weight	(freezed till here)
147: vitb16.encoder.layers.encoder_layer_11.mlp.3.bias	(freezed till here)
148: vitb16.encoder.ln.weight	(freezed till here)
149: vitb16.encoder.ln.bias	(freezed till here)
150: vitb16.heads.0.weight	(freezed till here)
151: vitb16.heads.0.bias	(freezed till here)
=============================================================


=============================================================================================================================
Layer (type:depth-idx)                             Input Shape               Output Shape              Param #
=============================================================================================================================
VIT_B16                                            [1, 1, 224, 224]          [1, 3]                    --
├─VisionTransformer: 1-1                           [1, 1, 224, 224]          [1, 3]                    768
│    └─Conv2d: 2-1                                 [1, 1, 224, 224]          [1, 768, 14, 14]          197,376
│    └─Encoder: 2-2                                [1, 197, 768]             [1, 197, 768]             151,296
│    │    └─Dropout: 3-1                           [1, 197, 768]             [1, 197, 768]             --
│    │    └─Sequential: 3-2                        [1, 197, 768]             [1, 197, 768]             85,054,464
│    │    └─LayerNorm: 3-3                         [1, 197, 768]             [1, 197, 768]             1,536
│    └─Sequential: 2-3                             [1, 768]                  [1, 3]                    --
│    │    └─Linear: 3-4                            [1, 768]                  [1, 3]                    2,307
=============================================================================================================================
Total params: 85,407,747
Trainable params: 85,407,747
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 95.40
=============================================================================================================================
Input size (MB): 0.20
Forward/backward pass size (MB): 104.09
Params size (MB): 227.63
Estimated Total Size (MB): 331.92
=============================================================================================================================